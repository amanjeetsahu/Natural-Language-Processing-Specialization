{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import unicodedata as ud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "np.random.seed(0)\n",
    "plt.style.use(\"ggplot\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data train\n",
    "df_train = pd.read_csv(f'./data/VLSP2013_POS_train_BI_POS_Column.txt', sep='\\t', encoding='utf-8', skip_blank_lines=False, header=None)\n",
    "# Đổi tên các cột.\n",
    "df_train.columns = ('Words','Tags')\n",
    "# Đưa về dạng chữ thường.\n",
    "df_train[\"Words\"]=df_train[\"Words\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data test\n",
    "df_test = pd.read_csv(f'./data/VLSP2013_POS_test_BI_POS_Column.txt', sep='\\t', encoding='utf-8', skip_blank_lines=False, header=None)\n",
    "# Đổi tên các cột.\n",
    "df_test.columns = ('Words','Tags')\n",
    "# Đưa về dạng chữ thường.\n",
    "df_test[\"Words\"]=df_train[\"Words\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data dev\n",
    "df_dev = pd.read_csv(f'./data/VLSP2013_POS_dev_BI_POS_Column.txt', sep='\\t', encoding='utf-8', skip_blank_lines=False, header=None)\n",
    "# Đổi tên các cột.\n",
    "df_dev.columns = ('Words','Tags')\n",
    "# Đưa về dạng chữ thường.\n",
    "df_dev[\"Words\"]=df_dev[\"Words\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hải_tặc</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eo_biển</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>malacca</td>\n",
       "      <td>Np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kỳ</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>)</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>:</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eo_biển</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>không</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yên_tĩnh</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>...</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>đó</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>là</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>con</td>\n",
       "      <td>Nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>đường</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biển</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ngắn</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nhất</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words Tags\n",
       "0    hải_tặc    N\n",
       "1    eo_biển    N\n",
       "2    malacca   Np\n",
       "3          (   CH\n",
       "4         kỳ    N\n",
       "5          1    M\n",
       "6          )   CH\n",
       "7          :   CH\n",
       "8    eo_biển    N\n",
       "9      không    R\n",
       "10  yên_tĩnh    A\n",
       "11       ...   CH\n",
       "12       NaN  NaN\n",
       "13        đó    P\n",
       "14        là    V\n",
       "15       con   Nc\n",
       "16     đường    N\n",
       "17      biển    N\n",
       "18      ngắn    A\n",
       "19      nhất    A"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh dấu stt câu theo vị trí của dấu chấm\n",
    "def mark_sentences(tmp):\n",
    "    sentences_index = [0]\n",
    "    y = 0\n",
    "    for i in range(len(tmp)):\n",
    "        for _ in range(int(tmp[i]-y)):\n",
    "            sentences_index.append(i)\n",
    "        y = tmp[i]\n",
    "    return sentences_index\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm các vị trí trong tập train có tag = NaN => kết thúc câu\n",
    "list_index = df_train[df_train['Tags'].isnull()].index\n",
    "list_mark_sentences = mark_sentences(list_index)\n",
    "df_train['Sentences'] = list_mark_sentences\n",
    "df_train.drop(list_index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm các vị trí trong tập train có tag = NaN => kết thúc câu\n",
    "list_index = df_test[df_test['Tags'].isnull()].index\n",
    "list_mark_sentences = mark_sentences(list_index)\n",
    "df_test['Sentences'] = list_mark_sentences\n",
    "df_test.drop(list_index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm các vị trí trong tập train có tag = NaN => kết thúc câu\n",
    "list_index = df_dev[df_dev['Tags'].isnull()].index\n",
    "list_mark_sentences = mark_sentences(list_index)\n",
    "df_dev['Sentences'] = list_mark_sentences\n",
    "df_dev.drop(list_index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng nhãn.\n",
    "print((df_dev['Tags'].nunique()))\n",
    "print((df_test['Tags'].nunique()))\n",
    "print((df_train['Tags'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Tags\"].replace(',', 'CH', inplace=True)\n",
    "# format nhãn B.\n",
    "df_train['Tags'].replace(['Ab', 'Cb', 'Eb', 'Mb', 'Nb', 'Pb', 'Vb'],\n",
    "                         ['B', 'B', 'B', 'B', 'B', 'B', 'B'], inplace=True)\n",
    "# format nhãn Y.\n",
    "df_train['Tags'].replace(['Ny', 'Vy', 'Xy'],\n",
    "                         ['Y', 'Y', 'Y'], inplace=True)\n",
    "# format nhãn B.\n",
    "df_dev['Tags'].replace(['Ab', 'Cb', 'Eb', 'Mb', 'Nb', 'Pb', 'Vb'],\n",
    "                       ['B', 'B', 'B', 'B', 'B', 'B', 'B'], inplace=True)\n",
    "# format nhãn Y.\n",
    "df_dev['Tags'].replace(['Ny', 'Vy', 'Xy'],\n",
    "                       ['Y', 'Y', 'Y'], inplace=True)\n",
    "\n",
    "# format nhãn B.\n",
    "df_test['Tags'].replace(['Ab', 'Cb', 'Eb', 'Mb', 'Nb', 'Pb', 'Vb'],\n",
    "                        ['B', 'B', 'B', 'B', 'B', 'B', 'B'], inplace=True)\n",
    "# format nhãn Y.\n",
    "df_test['Tags'].replace(['Ny', 'Vy', 'Xy', 'NY'],\n",
    "                        ['Y', 'Y', 'Y', 'Y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print((df_dev['Tags'].nunique()))\n",
    "print((df_test['Tags'].nunique()))\n",
    "print((df_train['Tags'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>11509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304459</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>13439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>13693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>13701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words Tags  Sentences\n",
       "257911   NaN    N      11509\n",
       "304459   NaN    N      13439\n",
       "310763   NaN    N      13693\n",
       "310930   NaN    N      13701"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['Words'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay thế các word là từ nan bị đánh dấu là NaN\n",
    "df_dev=df_dev.fillna('nan')\n",
    "df_train=df_train.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(df):\n",
    "    arg_func = lambda s : [(w,t) for w, t in zip(s['Words'].values.tolist(), s['Tags'].values.tolist())]\n",
    "    grouped = df.groupby('Sentences').apply(arg_func)\n",
    "    print(grouped)\n",
    "    sentences = [s for s in grouped]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = get_sentences(df_train)\n",
    "sentences_test = get_sentences(df_test)\n",
    "sentences_dev = get_sentences(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lưu_thông', 'V'), ('đường_biển', 'N'), ('của', 'N'), ('thế_giới', 'R'), (',', 'V'), ('đó', 'M'), ('là', 'N'), ('hải_trình', 'A'), ('lớn', 'A'), ('nhất', 'E'), ('từ', 'P'), ('tây', 'L'), ('sang', 'N'), ('đông', 'A'), ('với', 'E'), ('50.000', 'N'), ('lượt', 'A'), ('tàu_bè', 'CH')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences_dev:\n",
    "    sentences_train.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo ra file mới với words đã được gán tags từ tập train và test\n",
    "\n",
    "with open('./data/test_words_tags.txt','w', encoding='utf-8') as f:\n",
    "    for sentence in sentences_test:\n",
    "        for z in sentence:\n",
    "            f.write(f'{z[0]}\\t{z[1]}\\n')\n",
    "        f.write(f'\\n')\n",
    "with open('./data/train_words_tags.txt','w', encoding='utf-8') as f:\n",
    "    for sentence in sentences_train:\n",
    "        for z in sentence:\n",
    "            f.write(f'{z[0]}\\t{z[1]}\\n')\n",
    "        f.write(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo ra file mới với chỉ có words từ tập train và test\n",
    "\n",
    "with open('./data/test_words.txt','w', encoding='utf-8') as f:\n",
    "    for sentence in sentences_test:\n",
    "        for z in sentence:\n",
    "            f.write(f'{z[0]}\\n')\n",
    "        f.write(f'\\n')\n",
    "with open('./data/train_words.txt','w', encoding='utf-8') as f:\n",
    "    for sentence in sentences_train:\n",
    "        for z in sentence:\n",
    "            f.write(f'{z[0]}\\n')\n",
    "        f.write(f'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng tập từ vựng\n",
    "words_1 = tuple(df_train['Words'].values)\n",
    "words_2 = tuple(df_test['Words'].values)\n",
    "words = [x for x in set(words_1+words_2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = {w: i+2 for i, w in enumerate(words)}\n",
    "vocabs['--n--'] = 0\n",
    "vocabs['--unk--'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22505\n",
      "mắt 2\n",
      "khò 3\n",
      "mbc 4\n",
      "lừa_đảo 5\n",
      "phó_viện_trưởng 6\n",
      "mỏi_mòn 7\n",
      "xé_rào 8\n",
      "csiro 9\n",
      "đường_sá 10\n",
      "lâm_nghiệp 11\n",
      "dẹt 12\n",
      "hiệp_hội 13\n",
      "đồng_minh 14\n",
      "trao_tặng 15\n",
      "35 16\n",
      "nguyễn_bá_thụ 17\n",
      "ampli 18\n",
      "ngoại_tỉnh 19\n",
      "tôt 20\n",
      "trung_bình 21\n",
      "nhúng 22\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabs))\n",
    "count = 0\n",
    "for key, value in vocabs.items():\n",
    "    print(key, value)\n",
    "    count += 1\n",
    "    if count > 20: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý các từ chưa có trong vocabs (chưa có tags)\n",
    "\n",
    "def preprocess(vocabs, path):\n",
    "    data = []\n",
    "    file = open(path, encoding='utf-8').readlines()\n",
    "    for word in file:\n",
    "        if not word.split(): # Nếu là khoảng trắng sẽ là --n--\n",
    "            word = '--n--'\n",
    "            data.append(word)\n",
    "            continue\n",
    "        elif word.strip() not in vocabs: # Nếu từ đó không có trong vocab sẽ là --unk--\n",
    "            word = '--unk--'\n",
    "            data.append(word)\n",
    "            continue\n",
    "        data.append(word.strip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tag_counts(words_tags):\n",
    "    tags = [word_tag.split()[1] for word_tag in words_tags if word_tag.split()]\n",
    "    tag_counts = pd.DataFrame(tags)[0].value_counts()\n",
    "    tag_counts.plot.bar(rot=0, width=0.7, legend=False, figsize=(15, 5))\n",
    "    return pd.DataFrame(tag_counts).T.assign(Total=tag_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập train_gold: 659653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hải_tặc\\tN\\n', 'eo_biển\\tN\\n', 'malacca\\tNp\\n', '(\\tCH\\n', 'kỳ\\tN\\n']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words_tags = open('./data/train_words_tags.txt', encoding='utf-8').readlines()\n",
    "print('Số lượng từ trong tập train_gold:', len(train_words_tags))\n",
    "train_words_tags[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập train_words: 659653\n"
     ]
    }
   ],
   "source": [
    "train_words = preprocess(vocabs, './data/train_words.txt')\n",
    "print('Số lượng từ trong tập train_words:', len(train_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các từ không nằm trong vocabs\n",
    "arr = []\n",
    "for word_tag, word in zip(train_words_tags, train_words):\n",
    "    if word == '--unk--':\n",
    "        arr.append(word_tag.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập test_words: 68466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hải_tặc', 'eo_biển', 'malacca', '(', 'kỳ']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = preprocess(vocabs, './data/test_words.txt')\n",
    "print('Số lượng từ trong tập test_words:', len(test_words))\n",
    "test_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words_tags = open('./data/test_words_tags.txt', encoding='utf-8').readlines()\n",
    "print('Các từ không nằm trong vocabs', end=': ')\n",
    "for word_tag, word in zip(test_words_tags, test_words):\n",
    "    if word == '--unk--': print(word_tag.split()[0], end=', ')\n",
    "plot_tag_counts(test_words_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phần 3: Gán nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_word_tags(word_tag, vocabs):  # Gán nhãn cho các từ\n",
    "    if not word_tag.split():\n",
    "        word = '--n--'\n",
    "        tag = '--s--'\n",
    "    else:\n",
    "        word, tag = word_tag.split()\n",
    "        if word not in vocabs:\n",
    "            word = '--unk--'\n",
    "    return word, tag\n",
    "\n",
    "\n",
    "def create_dictionary(train_words_tags, vocabs):\n",
    "    emission_count = defaultdict(int)\n",
    "    transition_count = defaultdict(int)\n",
    "    tag_count = defaultdict(int)\n",
    "\n",
    "    pre_tag = '--s--'\n",
    "\n",
    "    for word_tag in train_words_tags:\n",
    "        word, tag = seperate_word_tags(word_tag, vocabs)\n",
    "        transition_count[(pre_tag, tag)] += 1\n",
    "        emission_count[(tag, word)] += 1\n",
    "        tag_count[tag] += 1\n",
    "        pre_tag = tag\n",
    "    return transition_count, emission_count, tag_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số nhãn: 22\n",
      "['--s--', 'A', 'B', 'C', 'CH', 'Cc', 'E', 'I', 'L', 'M', 'N', 'Nc', 'Ni', 'Np', 'Nu', 'P', 'R', 'T', 'V', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "transition_count, emission_count, tag_count = create_dictionary(train_words_tags, vocabs)\n",
    "states = sorted(tag_count.keys())\n",
    "print('Số nhãn:', len(states))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transition examples: \")\n",
    "for example in transition_count.items():\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos(words, words_tags, emission_count, vocabs, states):\n",
    "    num_correct = 0\n",
    "    for word, word_tag in zip(words, words_tags):\n",
    "        word_tag = word_tag.split()\n",
    "        if len(word_tag) !=2:\n",
    "            continue\n",
    "        else:\n",
    "            true_label = word_tag[1]\n",
    "        \n",
    "        max_count = 0\n",
    "        tag_final = ''\n",
    "        \n",
    "        if word not in vocabs:\n",
    "            continue\n",
    "        for tag in states:\n",
    "            if(tag,word) not in emission_count: \n",
    "                continue\n",
    "            count = emission_count[(tag, word)]\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                tag_final = tag\n",
    "        if tag_final == true_label:\n",
    "            num_correct +=1\n",
    "    accuracy = num_correct/len(words_tags)\n",
    "    return accuracy\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập train: 0.8801582043892774\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(train_words, train_words_tags, emission_count, vocabs, states)\n",
    "print('Độ chính xác trên tập train:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
